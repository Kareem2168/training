{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2-training hyperparameter ANN",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oASqOVojOOwM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd \n",
        "import seaborn as sns \n",
        "from google.colab import files \n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('Chapter6_PVT Data.csv')\n",
        "df.head(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "0STVBAuFOcEK",
        "outputId": "d5ebd21c-8e9d-468e-97ca-04eb456f520b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Temperature          Rs  Gas Gravity    Oil API          Pbp\n",
              "0   124.224811  983.507201     1.095773  27.378218  3094.473796"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7f3a2f41-097b-4f5f-870b-7ff7aba4ca11\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Rs</th>\n",
              "      <th>Gas Gravity</th>\n",
              "      <th>Oil API</th>\n",
              "      <th>Pbp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>124.224811</td>\n",
              "      <td>983.507201</td>\n",
              "      <td>1.095773</td>\n",
              "      <td>27.378218</td>\n",
              "      <td>3094.473796</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f3a2f41-097b-4f5f-870b-7ff7aba4ca11')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7f3a2f41-097b-4f5f-870b-7ff7aba4ca11 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7f3a2f41-097b-4f5f-870b-7ff7aba4ca11');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=df.drop(['Pbp'], axis='columns')\n",
        "y=df['Pbp']\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test= train_test_split(x,y,test_size=0.3, random_state=50)\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler=MinMaxScaler()\n",
        "X_train=scaler.fit_transform(x_train)\n",
        "X_test=scaler.transform(x_test)"
      ],
      "metadata": {
        "id": "97imJ2oCOrI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras-tuner\n"
      ],
      "metadata": {
        "id": "hpHex3ZkO_3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow"
      ],
      "metadata": {
        "id": "YnZN3TH4UMPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "from keras_tuner import RandomSearch, Hyperband\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        " \n",
        "from keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "ALLXBgMSO7Lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_builder(hp):\n",
        "  model=Sequential()\n",
        "  for i in range(hp.Int('nb_of_layers', 2,20)):\n",
        "    hp_units=hp.Int('units'+str(i), min_value=5, max_value=30)\n",
        "    hp_act=hp.Choice('activation fn'+str(i),values=['relu', 'tanh', 'sigmoid'])\n",
        "\n",
        "    model.add(Dense(units=hp_units, activation=hp_act, input_dim=4))\n",
        "  model.add(Dense(1))\n",
        "  hp_loss=hp.Choice('loss', values=['mse', 'msle'])\n",
        "\n",
        "  model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate',values=[1e-1, 1e-2, 1e-3, 1e-4])), loss=hp_loss)\n",
        "  return model\n",
        "\n",
        "tuner=RandomSearch(model_builder, objective='val_mean_squared_error',max_trials=10, seed=50)\n",
        "early_stop=EarlyStopping(patience=2,  monitor='val_mean_squared_error')\n",
        "tuner.search(X_train, y_train,callbacks=[early_stop], epochs=10,  validation_data=(X_test, y_test))\n",
        "\n",
        "best_hp=tuner.get_best_hyperparameters()[0]\n",
        "h_model=tuner.hypermodel.build(best_hp)\n",
        "h_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EA2Go-C-O-x0",
        "outputId": "7d6bef6b-119f-41c9-d4ac-2cc9bbffb8e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Reloading Oracle from existing project ./untitled_project/oracle.json\n",
            "INFO:tensorflow:Reloading Tuner from ./untitled_project/tuner0.json\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "Model: \"sequential_47\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_180 (Dense)           (None, 12)                60        \n",
            "                                                                 \n",
            " dense_181 (Dense)           (None, 12)                156       \n",
            "                                                                 \n",
            " dense_182 (Dense)           (None, 1)                 13        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 229\n",
            "Trainable params: 229\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.results_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inoYhaP0dX8h",
        "outputId": "52009b1b-61e1-45d6-a98e-9d2774a81f28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in ./untitled_project\n",
            "Showing 10 best trials\n",
            "<keras_tuner.engine.objective.Objective object at 0x7fd239013350>\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "nb of layers: 6\n",
            "units0: 12\n",
            "activation fn0: sigmoid\n",
            "units1: 12\n",
            "activation fn1: sigmoid\n",
            "learning_rate: 0.1\n",
            "loss: msle\n",
            "number_of_layers: 15\n",
            "units2: 13\n",
            "units3: 10\n",
            "units4: 13\n",
            "units5: 28\n",
            "units6: 26\n",
            "units7: 18\n",
            "units8: 8\n",
            "units9: 13\n",
            "units10: 28\n",
            "units11: 7\n",
            "units12: 7\n",
            "units13: 7\n",
            "units14: 7\n",
            "nb_of_layers: 2\n",
            "Score: 0.28720811009407043\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "nb of layers: 7\n",
            "units0: 8\n",
            "activation fn0: relu\n",
            "units1: 38\n",
            "activation fn1: sigmoid\n",
            "learning_rate: 0.1\n",
            "loss: msle\n",
            "number_of_layers: 3\n",
            "units2: 13\n",
            "units3: 27\n",
            "units4: 17\n",
            "units5: 16\n",
            "units6: 25\n",
            "units7: 26\n",
            "units8: 10\n",
            "units9: 13\n",
            "units10: 19\n",
            "Score: 0.8534305095672607\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "nb of layers: 2\n",
            "units0: 31\n",
            "activation fn0: relu\n",
            "units1: 19\n",
            "activation fn1: tanh\n",
            "learning_rate: 0.001\n",
            "loss: msle\n",
            "number_of_layers: 11\n",
            "units2: 7\n",
            "units3: 7\n",
            "units4: 7\n",
            "units5: 7\n",
            "units6: 7\n",
            "units7: 7\n",
            "units8: 7\n",
            "units9: 7\n",
            "units10: 7\n",
            "Score: 35.659908294677734\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "nb of layers: 4\n",
            "units0: 27\n",
            "activation fn0: sigmoid\n",
            "units1: 14\n",
            "activation fn1: relu\n",
            "learning_rate: 0.1\n",
            "loss: msle\n",
            "number_of_layers: 3\n",
            "units2: 12\n",
            "units3: 9\n",
            "units4: 17\n",
            "units5: 28\n",
            "units6: 20\n",
            "units7: 24\n",
            "units8: 16\n",
            "units9: 11\n",
            "units10: 15\n",
            "Score: 48.585182189941406\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "nb of layers: 7\n",
            "units0: 16\n",
            "activation fn0: tanh\n",
            "units1: 33\n",
            "activation fn1: relu\n",
            "learning_rate: 0.1\n",
            "loss: mse\n",
            "number_of_layers: 2\n",
            "Score: 35204.37109375\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "nb of layers: 12\n",
            "units0: 11\n",
            "activation fn0: sigmoid\n",
            "units1: 25\n",
            "activation fn1: relu\n",
            "learning_rate: 0.01\n",
            "loss: mse\n",
            "number_of_layers: 8\n",
            "units2: 15\n",
            "units3: 25\n",
            "units4: 18\n",
            "units5: 9\n",
            "units6: 24\n",
            "units7: 16\n",
            "units8: 20\n",
            "units9: 26\n",
            "units10: 21\n",
            "units11: 22\n",
            "units12: 19\n",
            "units13: 8\n",
            "units14: 15\n",
            "Score: 122262.3203125\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "nb of layers: 11\n",
            "units0: 16\n",
            "activation fn0: sigmoid\n",
            "units1: 47\n",
            "activation fn1: sigmoid\n",
            "learning_rate: 0.1\n",
            "loss: mse\n",
            "number_of_layers: 3\n",
            "units2: 29\n",
            "units3: 28\n",
            "units4: 20\n",
            "units5: 8\n",
            "units6: 29\n",
            "units7: 20\n",
            "units8: 19\n",
            "units9: 14\n",
            "units10: 16\n",
            "units11: 18\n",
            "units12: 18\n",
            "units13: 22\n",
            "units14: 20\n",
            "Score: 126978.5625\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "nb of layers: 3\n",
            "units0: 8\n",
            "activation fn0: tanh\n",
            "units1: 9\n",
            "activation fn1: tanh\n",
            "learning_rate: 0.01\n",
            "loss: mse\n",
            "number_of_layers: 11\n",
            "units2: 13\n",
            "units3: 20\n",
            "units4: 16\n",
            "units5: 20\n",
            "units6: 16\n",
            "units7: 10\n",
            "units8: 19\n",
            "units9: 8\n",
            "units10: 27\n",
            "units11: 29\n",
            "units12: 14\n",
            "units13: 23\n",
            "units14: 24\n",
            "Score: 129000.9609375\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "nb of layers: 3\n",
            "units0: 14\n",
            "activation fn0: relu\n",
            "units1: 40\n",
            "activation fn1: sigmoid\n",
            "learning_rate: 0.001\n",
            "loss: mse\n",
            "number_of_layers: 10\n",
            "units2: 27\n",
            "units3: 10\n",
            "units4: 21\n",
            "units5: 16\n",
            "units6: 9\n",
            "units7: 26\n",
            "units8: 23\n",
            "units9: 29\n",
            "units10: 30\n",
            "units11: 12\n",
            "units12: 20\n",
            "units13: 18\n",
            "units14: 21\n",
            "Score: 338871.03125\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "nb of layers: 10\n",
            "units0: 23\n",
            "activation fn0: relu\n",
            "units1: 28\n",
            "activation fn1: relu\n",
            "learning_rate: 0.001\n",
            "loss: mse\n",
            "number_of_layers: 2\n",
            "units2: 11\n",
            "units3: 12\n",
            "units4: 24\n",
            "units5: 13\n",
            "units6: 25\n",
            "units7: 25\n",
            "units8: 15\n",
            "units9: 14\n",
            "units10: 25\n",
            "units11: 17\n",
            "units12: 8\n",
            "units13: 29\n",
            "units14: 29\n",
            "Score: 1310236.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####################\n",
        "def model_builder(hp):\n",
        "  model=Sequential()\n",
        "  for i in range(hp.Int('nb_of_layers', 2,20)):\n",
        "    \n",
        "    \n",
        "\n",
        "    model.add(Dense(units=hp.Int('units'+str(i), min_value=5, max_value=30), activation=hp.Choice('activation fn'+str(i),values=['relu', 'tanh', 'sigmoid']), input_dim=4))\n",
        "  model.add(Dense(1))\n",
        "  hp_loss=hp.Choice('loss', values=['mse', 'msle'])\n",
        "\n",
        "  model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate',values=[1e-1, 1e-2, 1e-3, 1e-4])), loss=hp_loss)\n",
        "  return model\n",
        "\n",
        "tuner=Hyperband(model_builder, objective='val_loss',max_epochs=100, overwrite=True )\n",
        "early_stop=EarlyStopping(patience=2,  monitor='val_loss')\n",
        "tuner.search(X_train, y_train,callbacks=[early_stop], epochs=50,  validation_data=(X_test, y_test))\n",
        "\n",
        "best_hp=tuner.get_best_hyperparameters()[0]\n",
        "h_model=tuner.hypermodel.build(best_hp)\n",
        "h_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P0HbwddNZWka",
        "outputId": "fd90164a-24ec-493d-cc77-3966dfa410ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 00m 01s]\n",
            "val_loss: 2850834.25\n",
            "\n",
            "Best val_loss So Far: 37.4878044128418\n",
            "Total elapsed time: 00h 00m 09s\n",
            "\n",
            "Search: Running Trial #6\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "12                |5                 |nb_of_layers\n",
            "10                |9                 |units0\n",
            "tanh              |sigmoid           |activation fn0\n",
            "12                |6                 |units1\n",
            "sigmoid           |tanh              |activation fn1\n",
            "msle              |msle              |loss\n",
            "0.01              |0.001             |learning_rate\n",
            "18                |15                |units2\n",
            "relu              |tanh              |activation fn2\n",
            "12                |29                |units3\n",
            "tanh              |tanh              |activation fn3\n",
            "6                 |29                |units4\n",
            "sigmoid           |tanh              |activation fn4\n",
            "5                 |23                |units5\n",
            "tanh              |sigmoid           |activation fn5\n",
            "12                |7                 |units6\n",
            "relu              |relu              |activation fn6\n",
            "6                 |13                |units7\n",
            "tanh              |relu              |activation fn7\n",
            "12                |15                |units8\n",
            "relu              |tanh              |activation fn8\n",
            "26                |None              |units9\n",
            "sigmoid           |None              |activation fn9\n",
            "14                |None              |units10\n",
            "tanh              |None              |activation fn10\n",
            "27                |None              |units11\n",
            "sigmoid           |None              |activation fn11\n",
            "25                |None              |units12\n",
            "relu              |None              |activation fn12\n",
            "2                 |2                 |tuner/epochs\n",
            "0                 |0                 |tuner/initial_epoch\n",
            "4                 |4                 |tuner/bracket\n",
            "0                 |0                 |tuner/round\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0x7fd23f3b3f80>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/weakref.py\", line 358, in remove\n",
            "    def remove(k, selfref=ref(self)):\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "6/6 [==============================] - 1s 56ms/step - loss: 42.7526 - val_loss: 35.4756\n",
            "Epoch 2/2\n",
            "1/6 [====>.........................] - ETA: 0s - loss: 35.9883"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-123-d211bd1e7628>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtuner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHyperband\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_builder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mearly_stop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mbest_hp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0;31m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/tuners/hyperband.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuner/epochs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuner/initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHyperband\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         return tuner_utils.convert_to_metrics_dict(\n\u001b[1;32m    224\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HyperModel.fit()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/hypermodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1429\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1432\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1708\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1710\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1711\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m       raise RuntimeError(\"`tf.data.Dataset` only supports Python-style \"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0;34m\"When `dataset` is provided, `element_spec` and `components` must \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m             \"not be specified.\")\n\u001b[0;32m--> 755\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_call_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    785\u001b[0m                 \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m                 output_shapes=self._flat_output_shapes))\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m         \u001b[0;31m# Delete the resource when this object is deleted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         self._resource_deleter = IteratorResourceDeleter(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3314\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3315\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m-> 3316\u001b[0;31m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[0m\u001b[1;32m   3317\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3318\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.results_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DX3qJType3mo",
        "outputId": "2a0835e1-296c-4082-bc01-004e4e978356"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in ./untitled_project\n",
            "Showing 10 best trials\n",
            "<keras_tuner.engine.objective.Objective object at 0x7fd2387a7450>\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "nb_of_layers: 3\n",
            "units0: 23\n",
            "activation fn0: relu\n",
            "units1: 17\n",
            "activation fn1: relu\n",
            "loss: msle\n",
            "learning_rate: 0.1\n",
            "units2: 23\n",
            "activation fn2: relu\n",
            "units3: 24\n",
            "activation fn3: relu\n",
            "units4: 6\n",
            "activation fn4: tanh\n",
            "units5: 29\n",
            "activation fn5: sigmoid\n",
            "units6: 14\n",
            "activation fn6: sigmoid\n",
            "units7: 21\n",
            "activation fn7: sigmoid\n",
            "units8: 30\n",
            "activation fn8: tanh\n",
            "units9: 5\n",
            "activation fn9: relu\n",
            "units10: 15\n",
            "activation fn10: tanh\n",
            "units11: 18\n",
            "activation fn11: sigmoid\n",
            "units12: 22\n",
            "activation fn12: sigmoid\n",
            "units13: 6\n",
            "activation fn13: relu\n",
            "units14: 18\n",
            "activation fn14: relu\n",
            "units15: 26\n",
            "activation fn15: relu\n",
            "units16: 25\n",
            "activation fn16: relu\n",
            "units17: 28\n",
            "activation fn17: tanh\n",
            "units18: 24\n",
            "activation fn18: tanh\n",
            "units19: 11\n",
            "activation fn19: relu\n",
            "tuner/epochs: 4\n",
            "tuner/initial_epoch: 2\n",
            "tuner/bracket: 4\n",
            "tuner/round: 1\n",
            "tuner/trial_id: 0054\n",
            "Score: 0.9022902250289917\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "nb_of_layers: 3\n",
            "units0: 23\n",
            "activation fn0: relu\n",
            "units1: 17\n",
            "activation fn1: relu\n",
            "loss: msle\n",
            "learning_rate: 0.1\n",
            "units2: 23\n",
            "activation fn2: relu\n",
            "units3: 24\n",
            "activation fn3: relu\n",
            "units4: 6\n",
            "activation fn4: tanh\n",
            "units5: 29\n",
            "activation fn5: sigmoid\n",
            "units6: 14\n",
            "activation fn6: sigmoid\n",
            "units7: 21\n",
            "activation fn7: sigmoid\n",
            "units8: 30\n",
            "activation fn8: tanh\n",
            "units9: 5\n",
            "activation fn9: relu\n",
            "units10: 15\n",
            "activation fn10: tanh\n",
            "units11: 18\n",
            "activation fn11: sigmoid\n",
            "units12: 22\n",
            "activation fn12: sigmoid\n",
            "units13: 6\n",
            "activation fn13: relu\n",
            "units14: 18\n",
            "activation fn14: relu\n",
            "units15: 26\n",
            "activation fn15: relu\n",
            "units16: 25\n",
            "activation fn16: relu\n",
            "units17: 28\n",
            "activation fn17: tanh\n",
            "units18: 24\n",
            "activation fn18: tanh\n",
            "units19: 11\n",
            "activation fn19: relu\n",
            "tuner/epochs: 12\n",
            "tuner/initial_epoch: 4\n",
            "tuner/bracket: 4\n",
            "tuner/round: 2\n",
            "tuner/trial_id: 0098\n",
            "Score: 1.227608323097229\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "nb_of_layers: 3\n",
            "units0: 23\n",
            "activation fn0: relu\n",
            "units1: 17\n",
            "activation fn1: relu\n",
            "loss: msle\n",
            "learning_rate: 0.1\n",
            "units2: 23\n",
            "activation fn2: relu\n",
            "units3: 24\n",
            "activation fn3: relu\n",
            "units4: 6\n",
            "activation fn4: tanh\n",
            "units5: 29\n",
            "activation fn5: sigmoid\n",
            "units6: 14\n",
            "activation fn6: sigmoid\n",
            "units7: 21\n",
            "activation fn7: sigmoid\n",
            "units8: 30\n",
            "activation fn8: tanh\n",
            "units9: 5\n",
            "activation fn9: relu\n",
            "units10: 15\n",
            "activation fn10: tanh\n",
            "units11: 18\n",
            "activation fn11: sigmoid\n",
            "units12: 22\n",
            "activation fn12: sigmoid\n",
            "units13: 6\n",
            "activation fn13: relu\n",
            "units14: 18\n",
            "activation fn14: relu\n",
            "units15: 26\n",
            "activation fn15: relu\n",
            "units16: 25\n",
            "activation fn16: relu\n",
            "units17: 28\n",
            "activation fn17: tanh\n",
            "units18: 24\n",
            "activation fn18: tanh\n",
            "units19: 11\n",
            "activation fn19: relu\n",
            "tuner/epochs: 2\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 4\n",
            "tuner/round: 0\n",
            "Score: 1.3638814687728882\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "nb_of_layers: 4\n",
            "units0: 18\n",
            "activation fn0: relu\n",
            "units1: 11\n",
            "activation fn1: tanh\n",
            "loss: msle\n",
            "learning_rate: 0.1\n",
            "units2: 18\n",
            "activation fn2: sigmoid\n",
            "units3: 20\n",
            "activation fn3: relu\n",
            "units4: 28\n",
            "activation fn4: relu\n",
            "units5: 25\n",
            "activation fn5: sigmoid\n",
            "units6: 6\n",
            "activation fn6: sigmoid\n",
            "units7: 6\n",
            "activation fn7: sigmoid\n",
            "units8: 9\n",
            "activation fn8: relu\n",
            "units9: 9\n",
            "activation fn9: relu\n",
            "units10: 20\n",
            "activation fn10: sigmoid\n",
            "units11: 6\n",
            "activation fn11: relu\n",
            "units12: 6\n",
            "activation fn12: tanh\n",
            "units13: 7\n",
            "activation fn13: relu\n",
            "units14: 11\n",
            "activation fn14: sigmoid\n",
            "units15: 26\n",
            "activation fn15: relu\n",
            "units16: 12\n",
            "activation fn16: sigmoid\n",
            "units17: 24\n",
            "activation fn17: relu\n",
            "units18: 22\n",
            "activation fn18: tanh\n",
            "units19: 22\n",
            "activation fn19: sigmoid\n",
            "tuner/epochs: 2\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 4\n",
            "tuner/round: 0\n",
            "Score: 5.658628940582275\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "nb_of_layers: 5\n",
            "units0: 14\n",
            "activation fn0: relu\n",
            "units1: 10\n",
            "activation fn1: relu\n",
            "loss: msle\n",
            "learning_rate: 0.01\n",
            "units2: 9\n",
            "activation fn2: sigmoid\n",
            "units3: 8\n",
            "activation fn3: relu\n",
            "units4: 21\n",
            "activation fn4: relu\n",
            "units5: 29\n",
            "activation fn5: sigmoid\n",
            "units6: 20\n",
            "activation fn6: tanh\n",
            "units7: 30\n",
            "activation fn7: tanh\n",
            "units8: 17\n",
            "activation fn8: relu\n",
            "units9: 15\n",
            "activation fn9: tanh\n",
            "units10: 23\n",
            "activation fn10: sigmoid\n",
            "units11: 23\n",
            "activation fn11: sigmoid\n",
            "units12: 27\n",
            "activation fn12: sigmoid\n",
            "units13: 25\n",
            "activation fn13: tanh\n",
            "units14: 15\n",
            "activation fn14: sigmoid\n",
            "units15: 20\n",
            "activation fn15: sigmoid\n",
            "units16: 16\n",
            "activation fn16: relu\n",
            "units17: 7\n",
            "activation fn17: tanh\n",
            "units18: 10\n",
            "activation fn18: relu\n",
            "units19: 9\n",
            "activation fn19: sigmoid\n",
            "tuner/epochs: 12\n",
            "tuner/initial_epoch: 4\n",
            "tuner/bracket: 4\n",
            "tuner/round: 2\n",
            "tuner/trial_id: 0125\n",
            "Score: 9.186707496643066\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "nb_of_layers: 4\n",
            "units0: 11\n",
            "activation fn0: tanh\n",
            "units1: 10\n",
            "activation fn1: tanh\n",
            "loss: msle\n",
            "learning_rate: 0.1\n",
            "units2: 10\n",
            "activation fn2: sigmoid\n",
            "units3: 16\n",
            "activation fn3: relu\n",
            "units4: 15\n",
            "activation fn4: tanh\n",
            "units5: 16\n",
            "activation fn5: sigmoid\n",
            "units6: 27\n",
            "activation fn6: sigmoid\n",
            "units7: 14\n",
            "activation fn7: relu\n",
            "units8: 19\n",
            "activation fn8: sigmoid\n",
            "units9: 27\n",
            "activation fn9: relu\n",
            "units10: 11\n",
            "activation fn10: sigmoid\n",
            "units11: 22\n",
            "activation fn11: sigmoid\n",
            "units12: 30\n",
            "activation fn12: sigmoid\n",
            "units13: 14\n",
            "activation fn13: tanh\n",
            "units14: 16\n",
            "activation fn14: tanh\n",
            "units15: 17\n",
            "activation fn15: relu\n",
            "units16: 23\n",
            "activation fn16: relu\n",
            "units17: 6\n",
            "activation fn17: tanh\n",
            "units18: 23\n",
            "activation fn18: relu\n",
            "units19: 23\n",
            "activation fn19: sigmoid\n",
            "tuner/epochs: 2\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 4\n",
            "tuner/round: 0\n",
            "Score: 9.344181060791016\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "nb_of_layers: 4\n",
            "units0: 11\n",
            "activation fn0: tanh\n",
            "units1: 10\n",
            "activation fn1: tanh\n",
            "loss: msle\n",
            "learning_rate: 0.1\n",
            "units2: 10\n",
            "activation fn2: sigmoid\n",
            "units3: 16\n",
            "activation fn3: relu\n",
            "units4: 15\n",
            "activation fn4: tanh\n",
            "units5: 16\n",
            "activation fn5: sigmoid\n",
            "units6: 27\n",
            "activation fn6: sigmoid\n",
            "units7: 14\n",
            "activation fn7: relu\n",
            "units8: 19\n",
            "activation fn8: sigmoid\n",
            "units9: 27\n",
            "activation fn9: relu\n",
            "units10: 11\n",
            "activation fn10: sigmoid\n",
            "units11: 22\n",
            "activation fn11: sigmoid\n",
            "units12: 30\n",
            "activation fn12: sigmoid\n",
            "units13: 14\n",
            "activation fn13: tanh\n",
            "units14: 16\n",
            "activation fn14: tanh\n",
            "units15: 17\n",
            "activation fn15: relu\n",
            "units16: 23\n",
            "activation fn16: relu\n",
            "units17: 6\n",
            "activation fn17: tanh\n",
            "units18: 23\n",
            "activation fn18: relu\n",
            "units19: 23\n",
            "activation fn19: sigmoid\n",
            "tuner/epochs: 4\n",
            "tuner/initial_epoch: 2\n",
            "tuner/bracket: 4\n",
            "tuner/round: 1\n",
            "tuner/trial_id: 0013\n",
            "Score: 9.953496932983398\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "nb_of_layers: 9\n",
            "units0: 26\n",
            "activation fn0: sigmoid\n",
            "units1: 19\n",
            "activation fn1: tanh\n",
            "loss: msle\n",
            "learning_rate: 0.1\n",
            "units2: 22\n",
            "activation fn2: relu\n",
            "units3: 11\n",
            "activation fn3: sigmoid\n",
            "units4: 23\n",
            "activation fn4: tanh\n",
            "units5: 26\n",
            "activation fn5: relu\n",
            "units6: 18\n",
            "activation fn6: tanh\n",
            "units7: 25\n",
            "activation fn7: relu\n",
            "units8: 29\n",
            "activation fn8: sigmoid\n",
            "units9: 12\n",
            "activation fn9: relu\n",
            "units10: 12\n",
            "activation fn10: sigmoid\n",
            "units11: 7\n",
            "activation fn11: relu\n",
            "units12: 9\n",
            "activation fn12: relu\n",
            "units13: 21\n",
            "activation fn13: tanh\n",
            "units14: 21\n",
            "activation fn14: sigmoid\n",
            "units15: 24\n",
            "activation fn15: sigmoid\n",
            "units16: 29\n",
            "activation fn16: relu\n",
            "units17: 12\n",
            "activation fn17: relu\n",
            "units18: 19\n",
            "activation fn18: tanh\n",
            "units19: 17\n",
            "activation fn19: tanh\n",
            "tuner/epochs: 12\n",
            "tuner/initial_epoch: 4\n",
            "tuner/bracket: 3\n",
            "tuner/round: 1\n",
            "tuner/trial_id: 0182\n",
            "Score: 11.436179161071777\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "nb_of_layers: 9\n",
            "units0: 26\n",
            "activation fn0: sigmoid\n",
            "units1: 19\n",
            "activation fn1: tanh\n",
            "loss: msle\n",
            "learning_rate: 0.1\n",
            "units2: 22\n",
            "activation fn2: relu\n",
            "units3: 11\n",
            "activation fn3: sigmoid\n",
            "units4: 23\n",
            "activation fn4: tanh\n",
            "units5: 26\n",
            "activation fn5: relu\n",
            "units6: 18\n",
            "activation fn6: tanh\n",
            "units7: 25\n",
            "activation fn7: relu\n",
            "units8: 29\n",
            "activation fn8: sigmoid\n",
            "units9: 12\n",
            "activation fn9: relu\n",
            "units10: 12\n",
            "activation fn10: sigmoid\n",
            "units11: 7\n",
            "activation fn11: relu\n",
            "units12: 9\n",
            "activation fn12: relu\n",
            "units13: 21\n",
            "activation fn13: tanh\n",
            "units14: 21\n",
            "activation fn14: sigmoid\n",
            "units15: 24\n",
            "activation fn15: sigmoid\n",
            "units16: 29\n",
            "activation fn16: relu\n",
            "units17: 12\n",
            "activation fn17: relu\n",
            "units18: 19\n",
            "activation fn18: tanh\n",
            "units19: 17\n",
            "activation fn19: tanh\n",
            "tuner/epochs: 4\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 3\n",
            "tuner/round: 0\n",
            "Score: 13.024001121520996\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "nb_of_layers: 16\n",
            "units0: 27\n",
            "activation fn0: relu\n",
            "units1: 11\n",
            "activation fn1: sigmoid\n",
            "loss: msle\n",
            "learning_rate: 0.01\n",
            "units2: 25\n",
            "activation fn2: sigmoid\n",
            "units3: 24\n",
            "activation fn3: sigmoid\n",
            "units4: 26\n",
            "activation fn4: sigmoid\n",
            "units5: 12\n",
            "activation fn5: relu\n",
            "units6: 19\n",
            "activation fn6: relu\n",
            "units7: 7\n",
            "activation fn7: relu\n",
            "units8: 10\n",
            "activation fn8: relu\n",
            "units9: 10\n",
            "activation fn9: relu\n",
            "units10: 22\n",
            "activation fn10: relu\n",
            "units11: 17\n",
            "activation fn11: sigmoid\n",
            "units12: 19\n",
            "activation fn12: tanh\n",
            "units13: 13\n",
            "activation fn13: sigmoid\n",
            "units14: 25\n",
            "activation fn14: sigmoid\n",
            "units15: 11\n",
            "activation fn15: tanh\n",
            "tuner/epochs: 100\n",
            "tuner/initial_epoch: 34\n",
            "tuner/bracket: 4\n",
            "tuner/round: 4\n",
            "tuner/trial_id: 0145\n",
            "Score: 13.632360458374023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FJFnV4tpfsT7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}