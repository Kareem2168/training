{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OOP in Neural Networks",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sUqDztjOI5NS"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt  \n",
        "import pandas as pd \n",
        "import seaborn as sns \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files \n",
        "files.upload() \n"
      ],
      "metadata": {
        "id": "aZoctcYZfpiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('Chapter6_PVT Data.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "GadSZtexftZ7",
        "outputId": "54c3ac6c-29a9-409a-fb05-5e24e586ab6d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Temperature           Rs  Gas Gravity    Oil API          Pbp\n",
              "0   124.224811   983.507201     1.095773  27.378218  3094.473796\n",
              "1   105.670201  1118.311927     1.264539  30.497141  2593.138497\n",
              "2   220.984279   255.071907     0.840619  37.779038  1118.302194\n",
              "3   244.728321    48.801731     1.109872  35.049613   232.011706\n",
              "4   104.153879    75.385002     0.889540  24.543380   421.236666"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2a194034-9917-47b0-b9cb-4befb397fa59\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Rs</th>\n",
              "      <th>Gas Gravity</th>\n",
              "      <th>Oil API</th>\n",
              "      <th>Pbp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>124.224811</td>\n",
              "      <td>983.507201</td>\n",
              "      <td>1.095773</td>\n",
              "      <td>27.378218</td>\n",
              "      <td>3094.473796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>105.670201</td>\n",
              "      <td>1118.311927</td>\n",
              "      <td>1.264539</td>\n",
              "      <td>30.497141</td>\n",
              "      <td>2593.138497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>220.984279</td>\n",
              "      <td>255.071907</td>\n",
              "      <td>0.840619</td>\n",
              "      <td>37.779038</td>\n",
              "      <td>1118.302194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244.728321</td>\n",
              "      <td>48.801731</td>\n",
              "      <td>1.109872</td>\n",
              "      <td>35.049613</td>\n",
              "      <td>232.011706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>104.153879</td>\n",
              "      <td>75.385002</td>\n",
              "      <td>0.889540</td>\n",
              "      <td>24.543380</td>\n",
              "      <td>421.236666</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a194034-9917-47b0-b9cb-4befb397fa59')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2a194034-9917-47b0-b9cb-4befb397fa59 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2a194034-9917-47b0-b9cb-4befb397fa59');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=df.drop(['Pbp'], axis='columns')\n",
        "y=df['Pbp']\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test= train_test_split(x,y,test_size=0.3, random_state=50)\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler=MinMaxScaler()\n",
        "X_train=scaler.fit_transform(x_train)\n",
        "X_test=scaler.transform(x_test)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aYRKE1YCixLF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras-tuner"
      ],
      "metadata": {
        "id": "-e84Mkh7QT-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow\n",
        "import keras_tuner as kt\n",
        "from keras_tuner import RandomSearch, Hyperband\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        " \n",
        "from keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "BJjJ2Uh5QQMI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#just an example \n",
        "#i will add the hyperparameters directly in the code "
      ],
      "metadata": {
        "id": "3tlJg0N6aZKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Hypermodel:\n",
        "  def __init__(self, units, input_dim):\n",
        "    self.model=Sequential()\n",
        "    self.dense=(self.model).add(Dense(units, 'relu', input_dim))\n",
        "    self.dense1=(self.model).add(Dense(1))\n",
        "    self.compile=(self.model).compile(optimizer='adam', loss='mse')\n",
        "  \n",
        "\n",
        " \n",
        "\n",
        "  def fit(self, epc):\n",
        "    self.earlystop=EarlyStopping(patience=3)\n",
        "    return (self.model).fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epc, callbacks=[self.earlystop])\n",
        "\n",
        "  def evaluate(self):\n",
        "    return (self.model).evaluate(X_test, y_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "CX9SLCYtQXf0"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hypermodel=Hypermodel(4,4)"
      ],
      "metadata": {
        "id": "cUDRQ4-5S53Z"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hypermodel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FDnUOlcY1SB",
        "outputId": "8820b280-b80f-4983-80d7-0ca52314b5c0"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.Hypermodel at 0x7f12387764d0>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hypermodel.fit(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhLjGsQ6W13j",
        "outputId": "ba1c4b63-2117-4ec4-e8b0-05de47004cce"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 2849399.5000 - val_loss: 2853545.7500\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 2849327.7500 - val_loss: 2853478.0000\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 2849255.0000 - val_loss: 2853406.5000\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 2849177.7500 - val_loss: 2853333.7500\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 2849098.0000 - val_loss: 2853260.0000\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 2849017.2500 - val_loss: 2853183.2500\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 2848933.5000 - val_loss: 2853104.5000\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 2848847.7500 - val_loss: 2853023.5000\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 2848757.7500 - val_loss: 2852940.0000\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 2848667.5000 - val_loss: 2852852.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1238690110>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hypermodel.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBI9GG5uZfQm",
        "outputId": "7f9a83c5-d0c8-4175-f57f-8cc8f683ba34"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 4ms/step - loss: 2852852.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2852852.0"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### here i will add the variables later and not directly in the code "
      ],
      "metadata": {
        "id": "VawJbq_dZ13y"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Hypermodel:\n",
        "  def __init__(self, units, input_dim, opt, loss):\n",
        "    self.model=Sequential()\n",
        "    self.dense=(self.model).add(Dense(units, 'relu', input_dim))\n",
        "    self.dense1=(self.model).add(Dense(1))\n",
        "    self.compile=(self.model).compile(optimizer=opt, loss=loss)\n",
        "  \n",
        "\n",
        " \n",
        "\n",
        "  def fit(self, epc, number, xtrain,ytrain,xtest, ytest):\n",
        "    self.earlystop=EarlyStopping(patience=number)\n",
        "    return (self.model).fit(xtrain, ytrain, validation_data=(xtest, ytest), epochs=epc, callbacks=[self.earlystop])\n",
        "\n",
        "  def evaluate(self,xtest, ytest):\n",
        "    return (self.model).evaluate(xtest, ytest)"
      ],
      "metadata": {
        "id": "NRsBjm3_alIo"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model=Hypermodel(10, 2,'adam', 'msle')"
      ],
      "metadata": {
        "id": "ZxVJU15HbGPP"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(100, 4,X_train, y_train, X_test, y_test)\n",
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5KlYKQVbcFn",
        "outputId": "37eac6b6-02e8-4d4d-f61c-9c5ce2c4878a"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 29.7841 - val_loss: 28.3291\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 29.6916 - val_loss: 28.2397\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 29.5996 - val_loss: 28.1510\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 29.5088 - val_loss: 28.0630\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 29.4184 - val_loss: 27.9757\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 29.3284 - val_loss: 27.8891\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 29.2394 - val_loss: 27.8030\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 29.1509 - val_loss: 27.7176\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 29.0635 - val_loss: 27.6327\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.9762 - val_loss: 27.5485\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 28.8897 - val_loss: 27.4649\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 28.8042 - val_loss: 27.3818\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 28.7188 - val_loss: 27.2995\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 28.6342 - val_loss: 27.2179\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 28.5500 - val_loss: 27.1369\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 28.4668 - val_loss: 27.0562\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 28.3839 - val_loss: 26.9759\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 28.3016 - val_loss: 26.8964\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 28.2199 - val_loss: 26.8175\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 28.1387 - val_loss: 26.7391\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 28.0582 - val_loss: 26.6612\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 27.9783 - val_loss: 26.5839\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 27.8987 - val_loss: 26.5072\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 27.8197 - val_loss: 26.4310\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 27.7414 - val_loss: 26.3552\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 27.6640 - val_loss: 26.2798\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 27.5862 - val_loss: 26.2048\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 27.5089 - val_loss: 26.1305\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 27.4326 - val_loss: 26.0566\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 27.3568 - val_loss: 25.9832\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 27.2814 - val_loss: 25.9104\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 27.2065 - val_loss: 25.8379\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 27.1318 - val_loss: 25.7660\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 27.0579 - val_loss: 25.6946\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 26.9844 - val_loss: 25.6239\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 26.9117 - val_loss: 25.5535\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 26.8392 - val_loss: 25.4833\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 26.7668 - val_loss: 25.4137\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 26.6953 - val_loss: 25.3444\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 26.6242 - val_loss: 25.2757\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 26.5534 - val_loss: 25.2075\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 26.4835 - val_loss: 25.1395\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 26.4133 - val_loss: 25.0721\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 26.3440 - val_loss: 25.0051\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 26.2749 - val_loss: 24.9384\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 26.2065 - val_loss: 24.8720\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 26.1380 - val_loss: 24.8062\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 26.0703 - val_loss: 24.7407\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 26.0028 - val_loss: 24.6757\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 25.9357 - val_loss: 24.6113\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 25.8695 - val_loss: 24.5468\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 25.8030 - val_loss: 24.4829\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 25.7373 - val_loss: 24.4192\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 25.6720 - val_loss: 24.3560\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 25.6065 - val_loss: 24.2934\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 25.5419 - val_loss: 24.2309\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 25.4780 - val_loss: 24.1686\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 25.4140 - val_loss: 24.1068\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 25.3502 - val_loss: 24.0456\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 25.2871 - val_loss: 23.9847\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 25.2244 - val_loss: 23.9240\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 25.1618 - val_loss: 23.8636\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 25.0995 - val_loss: 23.8035\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 25.0376 - val_loss: 23.7438\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 24.9764 - val_loss: 23.6843\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 24.9147 - val_loss: 23.6255\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 24.8540 - val_loss: 23.5668\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 24.7936 - val_loss: 23.5083\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 24.7334 - val_loss: 23.4502\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 24.6735 - val_loss: 23.3924\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 24.6141 - val_loss: 23.3348\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 24.5547 - val_loss: 23.2775\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 24.4956 - val_loss: 23.2206\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 24.4370 - val_loss: 23.1640\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 24.3787 - val_loss: 23.1080\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 24.3212 - val_loss: 23.0522\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 24.2635 - val_loss: 22.9968\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 24.2062 - val_loss: 22.9416\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 24.1495 - val_loss: 22.8866\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 24.0927 - val_loss: 22.8319\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 24.0364 - val_loss: 22.7774\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 23.9801 - val_loss: 22.7235\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 23.9247 - val_loss: 22.6697\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 23.8690 - val_loss: 22.6164\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 23.8137 - val_loss: 22.5633\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 23.7590 - val_loss: 22.5104\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 23.7044 - val_loss: 22.4578\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 23.6502 - val_loss: 22.4052\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 23.5960 - val_loss: 22.3530\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 23.5421 - val_loss: 22.3011\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 23.4887 - val_loss: 22.2493\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 23.4350 - val_loss: 22.1979\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 23.3821 - val_loss: 22.1465\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 23.3290 - val_loss: 22.0955\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 23.2764 - val_loss: 22.0448\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 23.2242 - val_loss: 21.9945\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 23.1723 - val_loss: 21.9442\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 23.1202 - val_loss: 21.8943\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 23.0687 - val_loss: 21.8447\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 23.0172 - val_loss: 21.7952\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 21.7952\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21.795204162597656"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####### tuning hyperparameters"
      ],
      "metadata": {
        "id": "P2_Xll5bb1fv"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_builder(hp):\n",
        "  model=Sequential()\n",
        "  for i in range(hp.Int('layers #', 2,20)):\n",
        "    hp_units=hp.Int('units'+str(i), 5,30, step=1)\n",
        "    model.add(Dense(hp_units, activation=hp.Choice('activation', values=['relu', 'sigmoid', 'tanh']),input_dim=4))\n",
        "  model.add(Dense(1))\n",
        "  model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-1, 1e-2, 1e-3])), loss=hp.Choice('loss', values=['mse', 'msle']))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "C5d7J6crb92S"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Tuner:\n",
        "  def __init__(self, max_epochs, patience):\n",
        "    self.hyperband=Hyperband(model_builder, objective='val_loss', max_epochs=max_epochs,seed=50)\n",
        "    self.earlys=EarlyStopping(patience=patience)\n",
        "\n",
        "  def search(self,xtrain, ytrain,xtest, ytest, epochs):\n",
        "    return (self.hyperband).search(xtrain, ytrain, validation_data=[xtest, ytest], epochs=epochs, callbacks=[self.earlys])\n",
        "\n",
        "  def get_best_hp(self):\n",
        "    self.gbhp=(self.hyperband).get_best_hyperparameters()[0]\n",
        "\n",
        "    return self.gbhp\n",
        "\n",
        "  def build(self):\n",
        "    self.build=(self.hyperband).hypermodel.build(self.gbhp)\n",
        "\n",
        "    return self.build\n",
        "\n",
        "  def summary(self):\n",
        "    return (self.build).summary()\n",
        "\n",
        "  def results(self):\n",
        "    (self.hyperband).results_summary()\n",
        "\n",
        "\n",
        "  def fit(self,xtrain, ytrain):\n",
        "    return (self.build).fit(xtrain, ytrain)\n",
        "\n",
        "  def evaluate(self, xtest, ytest):\n",
        "    return (self.build).evaluate(xtest, ytest)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vwt1yEYugZBd"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hyperband=Tuner(10, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5IrJ6XhjkkS",
        "outputId": "51b8efa4-e167-4a0f-9f31-901fc6287b23"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Reloading Oracle from existing project ./untitled_project/oracle.json\n",
            "INFO:tensorflow:Reloading Tuner from ./untitled_project/tuner0.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hyperband.search(X_train, y_train, X_test, y_test,10 )"
      ],
      "metadata": {
        "id": "sgYh22wwjpZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hyperband.get_best_hp()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mi5vskcGkKpb",
        "outputId": "5296fb1f-b739-4326-d90d-ebd803d3d9ee"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras_tuner.engine.hyperparameters.HyperParameters at 0x7f123824a610>"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hyperband.build()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sn5g_THupBeW",
        "outputId": "c043015d-7e6b-4bdb-eea9-84d9e37b4c71"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7f123c5f8d90>"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hyperband.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4tecbNhpHFu",
        "outputId": "296e1d5a-8249-470a-843a-d58c27e4d9ca"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 8)                 40        \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 14)                126       \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 19)                285       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 25)                500       \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 15)                390       \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 12)                192       \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 10)                130       \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 7)                 77        \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 6)                 48        \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 1)                 7         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,795\n",
            "Trainable params: 1,795\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hyperband.results()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-UepueGpJ_F",
        "outputId": "a9e0958c-0c4a-4b9b-f60a-1fff3f602dba"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in ./untitled_project\n",
            "Showing 10 best trials\n",
            "<keras_tuner.engine.objective.Objective object at 0x7f12344b4210>\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 9\n",
            "units0: 8\n",
            "activation: relu\n",
            "units1: 14\n",
            "learning_rate: 0.1\n",
            "loss: msle\n",
            "units2: 19\n",
            "units3: 25\n",
            "units4: 15\n",
            "units5: 12\n",
            "units6: 10\n",
            "units7: 7\n",
            "units8: 6\n",
            "units9: 14\n",
            "units10: 11\n",
            "units11: 13\n",
            "units12: 28\n",
            "units13: 24\n",
            "units14: 24\n",
            "units15: 7\n",
            "units16: 29\n",
            "units17: 12\n",
            "units18: 23\n",
            "tuner/epochs: 12\n",
            "tuner/initial_epoch: 4\n",
            "tuner/bracket: 4\n",
            "tuner/round: 2\n",
            "tuner/trial_id: 0101\n",
            "Score: 0.589185357093811\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 5\n",
            "units0: 23\n",
            "activation: relu\n",
            "units1: 9\n",
            "learning_rate: 0.01\n",
            "loss: msle\n",
            "units2: 18\n",
            "units3: 22\n",
            "units4: 15\n",
            "units5: 9\n",
            "units6: 8\n",
            "units7: 21\n",
            "units8: 25\n",
            "units9: 25\n",
            "units10: 12\n",
            "units11: 10\n",
            "units12: 26\n",
            "units13: 21\n",
            "units14: 18\n",
            "units15: 22\n",
            "units16: 14\n",
            "units17: 29\n",
            "units18: 9\n",
            "units19: 11\n",
            "tuner/epochs: 34\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 1\n",
            "tuner/round: 0\n",
            "Score: 0.6749839186668396\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 11\n",
            "units0: 30\n",
            "activation: relu\n",
            "units1: 27\n",
            "learning_rate: 0.001\n",
            "loss: msle\n",
            "units2: 13\n",
            "units3: 19\n",
            "units4: 26\n",
            "units5: 16\n",
            "units6: 29\n",
            "units7: 29\n",
            "units8: 16\n",
            "units9: 24\n",
            "units10: 27\n",
            "units11: 29\n",
            "units12: 28\n",
            "units13: 7\n",
            "units14: 27\n",
            "units15: 11\n",
            "units16: 7\n",
            "units17: 29\n",
            "units18: 22\n",
            "units19: 22\n",
            "tuner/epochs: 34\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 1\n",
            "tuner/round: 0\n",
            "Score: 0.7265802025794983\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 10\n",
            "units0: 21\n",
            "activation: relu\n",
            "units1: 13\n",
            "learning_rate: 0.01\n",
            "loss: msle\n",
            "units2: 23\n",
            "units3: 13\n",
            "units4: 22\n",
            "units5: 28\n",
            "units6: 24\n",
            "units7: 11\n",
            "units8: 18\n",
            "units9: 29\n",
            "units10: 29\n",
            "units11: 9\n",
            "units12: 15\n",
            "units13: 20\n",
            "units14: 9\n",
            "units15: 21\n",
            "units16: 14\n",
            "units17: 28\n",
            "units18: 21\n",
            "units19: 18\n",
            "tuner/epochs: 4\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 3\n",
            "tuner/round: 0\n",
            "Score: 0.735405445098877\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 19\n",
            "units0: 9\n",
            "activation: relu\n",
            "units1: 11\n",
            "learning_rate: 0.1\n",
            "loss: msle\n",
            "units2: 14\n",
            "units3: 10\n",
            "units4: 28\n",
            "units5: 9\n",
            "units6: 28\n",
            "units7: 11\n",
            "units8: 7\n",
            "units9: 16\n",
            "units10: 22\n",
            "units11: 29\n",
            "units12: 17\n",
            "units13: 15\n",
            "units14: 15\n",
            "units15: 28\n",
            "units16: 29\n",
            "units17: 17\n",
            "units18: 28\n",
            "units19: 18\n",
            "tuner/epochs: 100\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 0\n",
            "tuner/round: 0\n",
            "Score: 0.738095223903656\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 6\n",
            "units0: 29\n",
            "activation: relu\n",
            "units1: 26\n",
            "learning_rate: 0.01\n",
            "loss: msle\n",
            "units2: 7\n",
            "units3: 17\n",
            "units4: 17\n",
            "units5: 24\n",
            "units6: 9\n",
            "units7: 8\n",
            "units8: 10\n",
            "units9: 28\n",
            "units10: 28\n",
            "units11: 20\n",
            "units12: 21\n",
            "units13: 14\n",
            "units14: 20\n",
            "units15: 29\n",
            "units16: 23\n",
            "units17: 19\n",
            "units18: 12\n",
            "units19: 13\n",
            "tuner/epochs: 12\n",
            "tuner/initial_epoch: 4\n",
            "tuner/bracket: 3\n",
            "tuner/round: 1\n",
            "tuner/trial_id: 0168\n",
            "Score: 0.7428308129310608\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 10\n",
            "units0: 28\n",
            "activation: relu\n",
            "units1: 17\n",
            "learning_rate: 0.1\n",
            "loss: msle\n",
            "units2: 24\n",
            "units3: 26\n",
            "units4: 16\n",
            "units5: 26\n",
            "units6: 26\n",
            "units7: 7\n",
            "units8: 13\n",
            "units9: 25\n",
            "units10: 19\n",
            "units11: 28\n",
            "units12: 6\n",
            "units13: 10\n",
            "units14: 26\n",
            "units15: 6\n",
            "units16: 13\n",
            "units17: 30\n",
            "units18: 24\n",
            "tuner/epochs: 2\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 4\n",
            "tuner/round: 0\n",
            "Score: 0.7452578544616699\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 15\n",
            "units0: 7\n",
            "activation: relu\n",
            "units1: 22\n",
            "learning_rate: 0.1\n",
            "loss: msle\n",
            "units2: 11\n",
            "units3: 16\n",
            "units4: 15\n",
            "units5: 15\n",
            "units6: 15\n",
            "units7: 27\n",
            "units8: 8\n",
            "units9: 14\n",
            "units10: 28\n",
            "units11: 26\n",
            "units12: 26\n",
            "units13: 26\n",
            "units14: 18\n",
            "units15: 25\n",
            "units16: 28\n",
            "units17: 13\n",
            "units18: 6\n",
            "units19: 17\n",
            "tuner/epochs: 4\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 3\n",
            "tuner/round: 0\n",
            "Score: 0.7577259540557861\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 9\n",
            "units0: 5\n",
            "activation: relu\n",
            "units1: 29\n",
            "learning_rate: 0.1\n",
            "loss: msle\n",
            "units2: 24\n",
            "units3: 29\n",
            "units4: 9\n",
            "units5: 24\n",
            "units6: 18\n",
            "units7: 7\n",
            "units8: 11\n",
            "units9: 23\n",
            "units10: 27\n",
            "units11: 10\n",
            "units12: 10\n",
            "units13: 23\n",
            "units14: 26\n",
            "units15: 6\n",
            "units16: 14\n",
            "units17: 9\n",
            "units18: 10\n",
            "tuner/epochs: 2\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 4\n",
            "tuner/round: 0\n",
            "Score: 0.77533358335495\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 6\n",
            "units0: 29\n",
            "activation: relu\n",
            "units1: 26\n",
            "learning_rate: 0.01\n",
            "loss: msle\n",
            "units2: 7\n",
            "units3: 17\n",
            "units4: 17\n",
            "units5: 24\n",
            "units6: 9\n",
            "units7: 8\n",
            "units8: 10\n",
            "units9: 28\n",
            "units10: 28\n",
            "units11: 20\n",
            "units12: 21\n",
            "units13: 14\n",
            "units14: 20\n",
            "units15: 29\n",
            "units16: 23\n",
            "units17: 19\n",
            "units18: 12\n",
            "units19: 13\n",
            "tuner/epochs: 34\n",
            "tuner/initial_epoch: 12\n",
            "tuner/bracket: 3\n",
            "tuner/round: 2\n",
            "tuner/trial_id: 0191\n",
            "Score: 0.7942997217178345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hyperband.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSfKAcC9pQ0K",
        "outputId": "f53b8687-bce8-44ab-feae-b6982364cc6b"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 2s 6ms/step - loss: 16.8151\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1238792390>"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hyperband.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeYNoLi9pZhv",
        "outputId": "a762107e-a0be-42fc-fb40-8644a3af2742"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 7ms/step - loss: 6.9680\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.968031406402588"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### now i will join all in one code (and not several methods to be created )\n"
      ],
      "metadata": {
        "id": "KahzAZNWpdlZ"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Tuner:\n",
        "  def __init__(self, max_epochs, patience,xtrain, ytrain,xtest, ytest, epochs):\n",
        "    self.hyperband=Hyperband(model_builder, objective='val_loss', max_epochs=max_epochs,seed=50)\n",
        "    self.earlys=EarlyStopping(patience=patience)\n",
        "    self.search=(self.hyperband).search(xtrain, ytrain, validation_data=[xtest, ytest], epochs=epochs, callbacks=[self.earlys])\n",
        "    self.gbhp=(self.hyperband).get_best_hyperparameters()[0]\n",
        "    self.build=(self.hyperband).hypermodel.build(self.gbhp)\n",
        "    self.summary=(self.build).summary()\n",
        "    self.result=(self.hyperband).results_summary()\n",
        "    self.fit=(self.build).fit(xtrain, ytrain)\n",
        "    self.evaluate=(self.build).evaluate(xtest, ytest)\n",
        "\n"
      ],
      "metadata": {
        "id": "Znk-Wfxyp3aB"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mytune=Tuner(1,2,X_train, y_train, X_test, y_test, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKnUChNeq-Jr",
        "outputId": "a7d28451-3339-4893-d9eb-83b281c86c69"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 254 Complete [00h 00m 22s]\n",
            "val_loss: 2531229.75\n",
            "\n",
            "Best val_loss So Far: 0.589185357093811\n",
            "Total elapsed time: 00h 00m 59s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_19 (Dense)            (None, 8)                 40        \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 14)                126       \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 19)                285       \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 25)                500       \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 15)                390       \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 12)                192       \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 10)                130       \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 7)                 77        \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 6)                 48        \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 1)                 7         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,795\n",
            "Trainable params: 1,795\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Results summary\n",
            "Results in ./untitled_project\n",
            "Showing 10 best trials\n",
            "<keras_tuner.engine.objective.Objective object at 0x7f12316f2610>\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 9\n",
            "units0: 8\n",
            "activation: relu\n",
            "units1: 14\n",
            "learning_rate: 0.1\n",
            "loss: msle\n",
            "units2: 19\n",
            "units3: 25\n",
            "units4: 15\n",
            "units5: 12\n",
            "units6: 10\n",
            "units7: 7\n",
            "units8: 6\n",
            "units9: 14\n",
            "units10: 11\n",
            "units11: 13\n",
            "units12: 28\n",
            "units13: 24\n",
            "units14: 24\n",
            "units15: 7\n",
            "units16: 29\n",
            "units17: 12\n",
            "units18: 23\n",
            "tuner/epochs: 12\n",
            "tuner/initial_epoch: 4\n",
            "tuner/bracket: 4\n",
            "tuner/round: 2\n",
            "tuner/trial_id: 0101\n",
            "Score: 0.589185357093811\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 5\n",
            "units0: 23\n",
            "activation: relu\n",
            "units1: 9\n",
            "learning_rate: 0.01\n",
            "loss: msle\n",
            "units2: 18\n",
            "units3: 22\n",
            "units4: 15\n",
            "units5: 9\n",
            "units6: 8\n",
            "units7: 21\n",
            "units8: 25\n",
            "units9: 25\n",
            "units10: 12\n",
            "units11: 10\n",
            "units12: 26\n",
            "units13: 21\n",
            "units14: 18\n",
            "units15: 22\n",
            "units16: 14\n",
            "units17: 29\n",
            "units18: 9\n",
            "units19: 11\n",
            "tuner/epochs: 34\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 1\n",
            "tuner/round: 0\n",
            "Score: 0.6749839186668396\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 11\n",
            "units0: 30\n",
            "activation: relu\n",
            "units1: 27\n",
            "learning_rate: 0.001\n",
            "loss: msle\n",
            "units2: 13\n",
            "units3: 19\n",
            "units4: 26\n",
            "units5: 16\n",
            "units6: 29\n",
            "units7: 29\n",
            "units8: 16\n",
            "units9: 24\n",
            "units10: 27\n",
            "units11: 29\n",
            "units12: 28\n",
            "units13: 7\n",
            "units14: 27\n",
            "units15: 11\n",
            "units16: 7\n",
            "units17: 29\n",
            "units18: 22\n",
            "units19: 22\n",
            "tuner/epochs: 34\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 1\n",
            "tuner/round: 0\n",
            "Score: 0.7265802025794983\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 10\n",
            "units0: 21\n",
            "activation: relu\n",
            "units1: 13\n",
            "learning_rate: 0.01\n",
            "loss: msle\n",
            "units2: 23\n",
            "units3: 13\n",
            "units4: 22\n",
            "units5: 28\n",
            "units6: 24\n",
            "units7: 11\n",
            "units8: 18\n",
            "units9: 29\n",
            "units10: 29\n",
            "units11: 9\n",
            "units12: 15\n",
            "units13: 20\n",
            "units14: 9\n",
            "units15: 21\n",
            "units16: 14\n",
            "units17: 28\n",
            "units18: 21\n",
            "units19: 18\n",
            "tuner/epochs: 4\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 3\n",
            "tuner/round: 0\n",
            "Score: 0.735405445098877\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 19\n",
            "units0: 9\n",
            "activation: relu\n",
            "units1: 11\n",
            "learning_rate: 0.1\n",
            "loss: msle\n",
            "units2: 14\n",
            "units3: 10\n",
            "units4: 28\n",
            "units5: 9\n",
            "units6: 28\n",
            "units7: 11\n",
            "units8: 7\n",
            "units9: 16\n",
            "units10: 22\n",
            "units11: 29\n",
            "units12: 17\n",
            "units13: 15\n",
            "units14: 15\n",
            "units15: 28\n",
            "units16: 29\n",
            "units17: 17\n",
            "units18: 28\n",
            "units19: 18\n",
            "tuner/epochs: 100\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 0\n",
            "tuner/round: 0\n",
            "Score: 0.738095223903656\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 6\n",
            "units0: 29\n",
            "activation: relu\n",
            "units1: 26\n",
            "learning_rate: 0.01\n",
            "loss: msle\n",
            "units2: 7\n",
            "units3: 17\n",
            "units4: 17\n",
            "units5: 24\n",
            "units6: 9\n",
            "units7: 8\n",
            "units8: 10\n",
            "units9: 28\n",
            "units10: 28\n",
            "units11: 20\n",
            "units12: 21\n",
            "units13: 14\n",
            "units14: 20\n",
            "units15: 29\n",
            "units16: 23\n",
            "units17: 19\n",
            "units18: 12\n",
            "units19: 13\n",
            "tuner/epochs: 12\n",
            "tuner/initial_epoch: 4\n",
            "tuner/bracket: 3\n",
            "tuner/round: 1\n",
            "tuner/trial_id: 0168\n",
            "Score: 0.7428308129310608\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 10\n",
            "units0: 28\n",
            "activation: relu\n",
            "units1: 17\n",
            "learning_rate: 0.1\n",
            "loss: msle\n",
            "units2: 24\n",
            "units3: 26\n",
            "units4: 16\n",
            "units5: 26\n",
            "units6: 26\n",
            "units7: 7\n",
            "units8: 13\n",
            "units9: 25\n",
            "units10: 19\n",
            "units11: 28\n",
            "units12: 6\n",
            "units13: 10\n",
            "units14: 26\n",
            "units15: 6\n",
            "units16: 13\n",
            "units17: 30\n",
            "units18: 24\n",
            "tuner/epochs: 2\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 4\n",
            "tuner/round: 0\n",
            "Score: 0.7452578544616699\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 15\n",
            "units0: 7\n",
            "activation: relu\n",
            "units1: 22\n",
            "learning_rate: 0.1\n",
            "loss: msle\n",
            "units2: 11\n",
            "units3: 16\n",
            "units4: 15\n",
            "units5: 15\n",
            "units6: 15\n",
            "units7: 27\n",
            "units8: 8\n",
            "units9: 14\n",
            "units10: 28\n",
            "units11: 26\n",
            "units12: 26\n",
            "units13: 26\n",
            "units14: 18\n",
            "units15: 25\n",
            "units16: 28\n",
            "units17: 13\n",
            "units18: 6\n",
            "units19: 17\n",
            "tuner/epochs: 4\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 3\n",
            "tuner/round: 0\n",
            "Score: 0.7577259540557861\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 9\n",
            "units0: 5\n",
            "activation: relu\n",
            "units1: 29\n",
            "learning_rate: 0.1\n",
            "loss: msle\n",
            "units2: 24\n",
            "units3: 29\n",
            "units4: 9\n",
            "units5: 24\n",
            "units6: 18\n",
            "units7: 7\n",
            "units8: 11\n",
            "units9: 23\n",
            "units10: 27\n",
            "units11: 10\n",
            "units12: 10\n",
            "units13: 23\n",
            "units14: 26\n",
            "units15: 6\n",
            "units16: 14\n",
            "units17: 9\n",
            "units18: 10\n",
            "tuner/epochs: 2\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 4\n",
            "tuner/round: 0\n",
            "Score: 0.77533358335495\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 6\n",
            "units0: 29\n",
            "activation: relu\n",
            "units1: 26\n",
            "learning_rate: 0.01\n",
            "loss: msle\n",
            "units2: 7\n",
            "units3: 17\n",
            "units4: 17\n",
            "units5: 24\n",
            "units6: 9\n",
            "units7: 8\n",
            "units8: 10\n",
            "units9: 28\n",
            "units10: 28\n",
            "units11: 20\n",
            "units12: 21\n",
            "units13: 14\n",
            "units14: 20\n",
            "units15: 29\n",
            "units16: 23\n",
            "units17: 19\n",
            "units18: 12\n",
            "units19: 13\n",
            "tuner/epochs: 34\n",
            "tuner/initial_epoch: 12\n",
            "tuner/bracket: 3\n",
            "tuner/round: 2\n",
            "tuner/trial_id: 0191\n",
            "Score: 0.7942997217178345\n",
            "6/6 [==============================] - 1s 4ms/step - loss: 21.8475\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 6.6459\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## creating a child class"
      ],
      "metadata": {
        "id": "JyQ7ycQtrKJL"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Tuner:\n",
        "  def __init__(self, max_epochs, patience):\n",
        "    self.hyperband=Hyperband(model_builder, objective='val_loss', max_epochs=max_epochs,seed=50)\n",
        "    self.earlys=EarlyStopping(patience=patience)\n",
        "\n",
        "\n",
        "class Best_HP(Tuner):\n",
        "  def __init__(self, max_epochs, patience,xtrain, ytrain,xtest, ytest, epochs):\n",
        "\n",
        "    #Tuner.__init__(self, max_epochs, patience) # can use this or\n",
        "    super().__init__(max_epochs, patience)# this \n",
        "    self.search=(self.hyperband).search(xtrain, ytrain, validation_data=[xtest, ytest], epochs=epochs, callbacks=[self.earlys])\n",
        "    self.gbhp=(self.hyperband).get_best_hyperparameters()[0]\n",
        "    self.build=(self.hyperband).hypermodel.build(self.gbhp)\n",
        "    self.summary=(self.build).summary()\n",
        "    self.result=(self.hyperband).results_summary()\n",
        "    self.fit=(self.build).fit(xtrain, ytrain)\n",
        "    self.evaluate=(self.build).evaluate(xtest, ytest)"
      ],
      "metadata": {
        "id": "jb7Rj13Irrrl"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_hp=Best_HP(1,2,X_train ,y_train, X_test, y_test,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWTe1paHtD2p",
        "outputId": "e647b5f8-477b-458e-a2b2-5d3ec43f0f08"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Reloading Oracle from existing project ./untitled_project/oracle.json\n",
            "INFO:tensorflow:Reloading Tuner from ./untitled_project/tuner0.json\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_90 (Dense)            (None, 8)                 40        \n",
            "                                                                 \n",
            " dense_91 (Dense)            (None, 14)                126       \n",
            "                                                                 \n",
            " dense_92 (Dense)            (None, 19)                285       \n",
            "                                                                 \n",
            " dense_93 (Dense)            (None, 25)                500       \n",
            "                                                                 \n",
            " dense_94 (Dense)            (None, 15)                390       \n",
            "                                                                 \n",
            " dense_95 (Dense)            (None, 12)                192       \n",
            "                                                                 \n",
            " dense_96 (Dense)            (None, 10)                130       \n",
            "                                                                 \n",
            " dense_97 (Dense)            (None, 7)                 77        \n",
            "                                                                 \n",
            " dense_98 (Dense)            (None, 6)                 48        \n",
            "                                                                 \n",
            " dense_99 (Dense)            (None, 1)                 7         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,795\n",
            "Trainable params: 1,795\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Results summary\n",
            "Results in ./untitled_project\n",
            "Showing 10 best trials\n",
            "<keras_tuner.engine.objective.Objective object at 0x7f1236bf3550>\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 9\n",
            "units0: 8\n",
            "activation: relu\n",
            "units1: 14\n",
            "learning_rate: 0.1\n",
            "loss: msle\n",
            "units2: 19\n",
            "units3: 25\n",
            "units4: 15\n",
            "units5: 12\n",
            "units6: 10\n",
            "units7: 7\n",
            "units8: 6\n",
            "units9: 14\n",
            "units10: 11\n",
            "units11: 13\n",
            "units12: 28\n",
            "units13: 24\n",
            "units14: 24\n",
            "units15: 7\n",
            "units16: 29\n",
            "units17: 12\n",
            "units18: 23\n",
            "tuner/epochs: 12\n",
            "tuner/initial_epoch: 4\n",
            "tuner/bracket: 4\n",
            "tuner/round: 2\n",
            "tuner/trial_id: 0101\n",
            "Score: 0.589185357093811\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 5\n",
            "units0: 23\n",
            "activation: relu\n",
            "units1: 9\n",
            "learning_rate: 0.01\n",
            "loss: msle\n",
            "units2: 18\n",
            "units3: 22\n",
            "units4: 15\n",
            "units5: 9\n",
            "units6: 8\n",
            "units7: 21\n",
            "units8: 25\n",
            "units9: 25\n",
            "units10: 12\n",
            "units11: 10\n",
            "units12: 26\n",
            "units13: 21\n",
            "units14: 18\n",
            "units15: 22\n",
            "units16: 14\n",
            "units17: 29\n",
            "units18: 9\n",
            "units19: 11\n",
            "tuner/epochs: 34\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 1\n",
            "tuner/round: 0\n",
            "Score: 0.6749839186668396\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 11\n",
            "units0: 30\n",
            "activation: relu\n",
            "units1: 27\n",
            "learning_rate: 0.001\n",
            "loss: msle\n",
            "units2: 13\n",
            "units3: 19\n",
            "units4: 26\n",
            "units5: 16\n",
            "units6: 29\n",
            "units7: 29\n",
            "units8: 16\n",
            "units9: 24\n",
            "units10: 27\n",
            "units11: 29\n",
            "units12: 28\n",
            "units13: 7\n",
            "units14: 27\n",
            "units15: 11\n",
            "units16: 7\n",
            "units17: 29\n",
            "units18: 22\n",
            "units19: 22\n",
            "tuner/epochs: 34\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 1\n",
            "tuner/round: 0\n",
            "Score: 0.7265802025794983\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 10\n",
            "units0: 21\n",
            "activation: relu\n",
            "units1: 13\n",
            "learning_rate: 0.01\n",
            "loss: msle\n",
            "units2: 23\n",
            "units3: 13\n",
            "units4: 22\n",
            "units5: 28\n",
            "units6: 24\n",
            "units7: 11\n",
            "units8: 18\n",
            "units9: 29\n",
            "units10: 29\n",
            "units11: 9\n",
            "units12: 15\n",
            "units13: 20\n",
            "units14: 9\n",
            "units15: 21\n",
            "units16: 14\n",
            "units17: 28\n",
            "units18: 21\n",
            "units19: 18\n",
            "tuner/epochs: 4\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 3\n",
            "tuner/round: 0\n",
            "Score: 0.735405445098877\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 19\n",
            "units0: 9\n",
            "activation: relu\n",
            "units1: 11\n",
            "learning_rate: 0.1\n",
            "loss: msle\n",
            "units2: 14\n",
            "units3: 10\n",
            "units4: 28\n",
            "units5: 9\n",
            "units6: 28\n",
            "units7: 11\n",
            "units8: 7\n",
            "units9: 16\n",
            "units10: 22\n",
            "units11: 29\n",
            "units12: 17\n",
            "units13: 15\n",
            "units14: 15\n",
            "units15: 28\n",
            "units16: 29\n",
            "units17: 17\n",
            "units18: 28\n",
            "units19: 18\n",
            "tuner/epochs: 100\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 0\n",
            "tuner/round: 0\n",
            "Score: 0.738095223903656\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 6\n",
            "units0: 29\n",
            "activation: relu\n",
            "units1: 26\n",
            "learning_rate: 0.01\n",
            "loss: msle\n",
            "units2: 7\n",
            "units3: 17\n",
            "units4: 17\n",
            "units5: 24\n",
            "units6: 9\n",
            "units7: 8\n",
            "units8: 10\n",
            "units9: 28\n",
            "units10: 28\n",
            "units11: 20\n",
            "units12: 21\n",
            "units13: 14\n",
            "units14: 20\n",
            "units15: 29\n",
            "units16: 23\n",
            "units17: 19\n",
            "units18: 12\n",
            "units19: 13\n",
            "tuner/epochs: 12\n",
            "tuner/initial_epoch: 4\n",
            "tuner/bracket: 3\n",
            "tuner/round: 1\n",
            "tuner/trial_id: 0168\n",
            "Score: 0.7428308129310608\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 10\n",
            "units0: 28\n",
            "activation: relu\n",
            "units1: 17\n",
            "learning_rate: 0.1\n",
            "loss: msle\n",
            "units2: 24\n",
            "units3: 26\n",
            "units4: 16\n",
            "units5: 26\n",
            "units6: 26\n",
            "units7: 7\n",
            "units8: 13\n",
            "units9: 25\n",
            "units10: 19\n",
            "units11: 28\n",
            "units12: 6\n",
            "units13: 10\n",
            "units14: 26\n",
            "units15: 6\n",
            "units16: 13\n",
            "units17: 30\n",
            "units18: 24\n",
            "tuner/epochs: 2\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 4\n",
            "tuner/round: 0\n",
            "Score: 0.7452578544616699\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 15\n",
            "units0: 7\n",
            "activation: relu\n",
            "units1: 22\n",
            "learning_rate: 0.1\n",
            "loss: msle\n",
            "units2: 11\n",
            "units3: 16\n",
            "units4: 15\n",
            "units5: 15\n",
            "units6: 15\n",
            "units7: 27\n",
            "units8: 8\n",
            "units9: 14\n",
            "units10: 28\n",
            "units11: 26\n",
            "units12: 26\n",
            "units13: 26\n",
            "units14: 18\n",
            "units15: 25\n",
            "units16: 28\n",
            "units17: 13\n",
            "units18: 6\n",
            "units19: 17\n",
            "tuner/epochs: 4\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 3\n",
            "tuner/round: 0\n",
            "Score: 0.7577259540557861\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 9\n",
            "units0: 5\n",
            "activation: relu\n",
            "units1: 29\n",
            "learning_rate: 0.1\n",
            "loss: msle\n",
            "units2: 24\n",
            "units3: 29\n",
            "units4: 9\n",
            "units5: 24\n",
            "units6: 18\n",
            "units7: 7\n",
            "units8: 11\n",
            "units9: 23\n",
            "units10: 27\n",
            "units11: 10\n",
            "units12: 10\n",
            "units13: 23\n",
            "units14: 26\n",
            "units15: 6\n",
            "units16: 14\n",
            "units17: 9\n",
            "units18: 10\n",
            "tuner/epochs: 2\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 4\n",
            "tuner/round: 0\n",
            "Score: 0.77533358335495\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 6\n",
            "units0: 29\n",
            "activation: relu\n",
            "units1: 26\n",
            "learning_rate: 0.01\n",
            "loss: msle\n",
            "units2: 7\n",
            "units3: 17\n",
            "units4: 17\n",
            "units5: 24\n",
            "units6: 9\n",
            "units7: 8\n",
            "units8: 10\n",
            "units9: 28\n",
            "units10: 28\n",
            "units11: 20\n",
            "units12: 21\n",
            "units13: 14\n",
            "units14: 20\n",
            "units15: 29\n",
            "units16: 23\n",
            "units17: 19\n",
            "units18: 12\n",
            "units19: 13\n",
            "tuner/epochs: 34\n",
            "tuner/initial_epoch: 12\n",
            "tuner/bracket: 3\n",
            "tuner/round: 2\n",
            "tuner/trial_id: 0191\n",
            "Score: 0.7942997217178345\n",
            "6/6 [==============================] - 1s 3ms/step - loss: 48.3146\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 4.7472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# i will put them all together now "
      ],
      "metadata": {
        "id": "sgxdNVkUwV2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Tuner:\n",
        "  def model_builder(hp):\n",
        "\n",
        "    model=Sequential()\n",
        "    for i in range(hp.Int('layers #', 2,20)):\n",
        "\n",
        "      hp_units=hp.Int('units'+str(i), 5,30, step=1)\n",
        "      model.add(Dense(hp_units, activation=hp.Choice('activation', values=['relu', 'sigmoid', 'tanh']),input_dim=4))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-1, 1e-2, 1e-3])), loss=hp.Choice('loss', values=['mse', 'msle']))\n",
        "\n",
        "    return model\n",
        "\n",
        "  def __init__(self, max_epochs, patience):\n",
        "    self.hyperband=Hyperband(model_builder, objective='val_loss', max_epochs=max_epochs,seed=50)\n",
        "    self.earlys=EarlyStopping(patience=patience)\n",
        "\n",
        "\n",
        "class Best_HP(Tuner):\n",
        "  def __init__(self, max_epochs, patience,xtrain, ytrain,xtest, ytest, epochs):\n",
        "\n",
        "    #Tuner.__init__(self, max_epochs, patience) # can use this or\n",
        "    super().__init__(max_epochs, patience)# this \n",
        "    self.search=(self.hyperband).search(xtrain, ytrain, validation_data=[xtest, ytest], epochs=epochs, callbacks=[self.earlys])\n",
        "    self.gbhp=(self.hyperband).get_best_hyperparameters()[0]\n",
        "    self.build=(self.hyperband).hypermodel.build(self.gbhp)\n",
        "    self.summary=(self.build).summary()\n",
        "    self.result=(self.hyperband).results_summary()\n",
        "    self.fit=(self.build).fit(xtrain, ytrain)\n",
        "    self.evaluate=(self.build).evaluate(xtest, ytest)"
      ],
      "metadata": {
        "id": "-bxRcebitPId"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_Hp=Best_HP(1,2,X_train ,y_train, X_test, y_test,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ed7OvqIJwMQS",
        "outputId": "8c90ca25-54ee-421d-8f43-d8bc6c412338"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Reloading Oracle from existing project ./untitled_project/oracle.json\n",
            "INFO:tensorflow:Reloading Tuner from ./untitled_project/tuner0.json\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_103 (Dense)           (None, 8)                 40        \n",
            "                                                                 \n",
            " dense_104 (Dense)           (None, 14)                126       \n",
            "                                                                 \n",
            " dense_105 (Dense)           (None, 19)                285       \n",
            "                                                                 \n",
            " dense_106 (Dense)           (None, 25)                500       \n",
            "                                                                 \n",
            " dense_107 (Dense)           (None, 15)                390       \n",
            "                                                                 \n",
            " dense_108 (Dense)           (None, 12)                192       \n",
            "                                                                 \n",
            " dense_109 (Dense)           (None, 10)                130       \n",
            "                                                                 \n",
            " dense_110 (Dense)           (None, 7)                 77        \n",
            "                                                                 \n",
            " dense_111 (Dense)           (None, 6)                 48        \n",
            "                                                                 \n",
            " dense_112 (Dense)           (None, 1)                 7         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,795\n",
            "Trainable params: 1,795\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Results summary\n",
            "Results in ./untitled_project\n",
            "Showing 10 best trials\n",
            "<keras_tuner.engine.objective.Objective object at 0x7f123676bd90>\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 9\n",
            "units0: 8\n",
            "activation: relu\n",
            "units1: 14\n",
            "learning_rate: 0.1\n",
            "loss: msle\n",
            "units2: 19\n",
            "units3: 25\n",
            "units4: 15\n",
            "units5: 12\n",
            "units6: 10\n",
            "units7: 7\n",
            "units8: 6\n",
            "units9: 14\n",
            "units10: 11\n",
            "units11: 13\n",
            "units12: 28\n",
            "units13: 24\n",
            "units14: 24\n",
            "units15: 7\n",
            "units16: 29\n",
            "units17: 12\n",
            "units18: 23\n",
            "tuner/epochs: 12\n",
            "tuner/initial_epoch: 4\n",
            "tuner/bracket: 4\n",
            "tuner/round: 2\n",
            "tuner/trial_id: 0101\n",
            "Score: 0.589185357093811\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 5\n",
            "units0: 23\n",
            "activation: relu\n",
            "units1: 9\n",
            "learning_rate: 0.01\n",
            "loss: msle\n",
            "units2: 18\n",
            "units3: 22\n",
            "units4: 15\n",
            "units5: 9\n",
            "units6: 8\n",
            "units7: 21\n",
            "units8: 25\n",
            "units9: 25\n",
            "units10: 12\n",
            "units11: 10\n",
            "units12: 26\n",
            "units13: 21\n",
            "units14: 18\n",
            "units15: 22\n",
            "units16: 14\n",
            "units17: 29\n",
            "units18: 9\n",
            "units19: 11\n",
            "tuner/epochs: 34\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 1\n",
            "tuner/round: 0\n",
            "Score: 0.6749839186668396\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 11\n",
            "units0: 30\n",
            "activation: relu\n",
            "units1: 27\n",
            "learning_rate: 0.001\n",
            "loss: msle\n",
            "units2: 13\n",
            "units3: 19\n",
            "units4: 26\n",
            "units5: 16\n",
            "units6: 29\n",
            "units7: 29\n",
            "units8: 16\n",
            "units9: 24\n",
            "units10: 27\n",
            "units11: 29\n",
            "units12: 28\n",
            "units13: 7\n",
            "units14: 27\n",
            "units15: 11\n",
            "units16: 7\n",
            "units17: 29\n",
            "units18: 22\n",
            "units19: 22\n",
            "tuner/epochs: 34\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 1\n",
            "tuner/round: 0\n",
            "Score: 0.7265802025794983\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 10\n",
            "units0: 21\n",
            "activation: relu\n",
            "units1: 13\n",
            "learning_rate: 0.01\n",
            "loss: msle\n",
            "units2: 23\n",
            "units3: 13\n",
            "units4: 22\n",
            "units5: 28\n",
            "units6: 24\n",
            "units7: 11\n",
            "units8: 18\n",
            "units9: 29\n",
            "units10: 29\n",
            "units11: 9\n",
            "units12: 15\n",
            "units13: 20\n",
            "units14: 9\n",
            "units15: 21\n",
            "units16: 14\n",
            "units17: 28\n",
            "units18: 21\n",
            "units19: 18\n",
            "tuner/epochs: 4\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 3\n",
            "tuner/round: 0\n",
            "Score: 0.735405445098877\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 19\n",
            "units0: 9\n",
            "activation: relu\n",
            "units1: 11\n",
            "learning_rate: 0.1\n",
            "loss: msle\n",
            "units2: 14\n",
            "units3: 10\n",
            "units4: 28\n",
            "units5: 9\n",
            "units6: 28\n",
            "units7: 11\n",
            "units8: 7\n",
            "units9: 16\n",
            "units10: 22\n",
            "units11: 29\n",
            "units12: 17\n",
            "units13: 15\n",
            "units14: 15\n",
            "units15: 28\n",
            "units16: 29\n",
            "units17: 17\n",
            "units18: 28\n",
            "units19: 18\n",
            "tuner/epochs: 100\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 0\n",
            "tuner/round: 0\n",
            "Score: 0.738095223903656\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 6\n",
            "units0: 29\n",
            "activation: relu\n",
            "units1: 26\n",
            "learning_rate: 0.01\n",
            "loss: msle\n",
            "units2: 7\n",
            "units3: 17\n",
            "units4: 17\n",
            "units5: 24\n",
            "units6: 9\n",
            "units7: 8\n",
            "units8: 10\n",
            "units9: 28\n",
            "units10: 28\n",
            "units11: 20\n",
            "units12: 21\n",
            "units13: 14\n",
            "units14: 20\n",
            "units15: 29\n",
            "units16: 23\n",
            "units17: 19\n",
            "units18: 12\n",
            "units19: 13\n",
            "tuner/epochs: 12\n",
            "tuner/initial_epoch: 4\n",
            "tuner/bracket: 3\n",
            "tuner/round: 1\n",
            "tuner/trial_id: 0168\n",
            "Score: 0.7428308129310608\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 10\n",
            "units0: 28\n",
            "activation: relu\n",
            "units1: 17\n",
            "learning_rate: 0.1\n",
            "loss: msle\n",
            "units2: 24\n",
            "units3: 26\n",
            "units4: 16\n",
            "units5: 26\n",
            "units6: 26\n",
            "units7: 7\n",
            "units8: 13\n",
            "units9: 25\n",
            "units10: 19\n",
            "units11: 28\n",
            "units12: 6\n",
            "units13: 10\n",
            "units14: 26\n",
            "units15: 6\n",
            "units16: 13\n",
            "units17: 30\n",
            "units18: 24\n",
            "tuner/epochs: 2\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 4\n",
            "tuner/round: 0\n",
            "Score: 0.7452578544616699\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 15\n",
            "units0: 7\n",
            "activation: relu\n",
            "units1: 22\n",
            "learning_rate: 0.1\n",
            "loss: msle\n",
            "units2: 11\n",
            "units3: 16\n",
            "units4: 15\n",
            "units5: 15\n",
            "units6: 15\n",
            "units7: 27\n",
            "units8: 8\n",
            "units9: 14\n",
            "units10: 28\n",
            "units11: 26\n",
            "units12: 26\n",
            "units13: 26\n",
            "units14: 18\n",
            "units15: 25\n",
            "units16: 28\n",
            "units17: 13\n",
            "units18: 6\n",
            "units19: 17\n",
            "tuner/epochs: 4\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 3\n",
            "tuner/round: 0\n",
            "Score: 0.7577259540557861\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 9\n",
            "units0: 5\n",
            "activation: relu\n",
            "units1: 29\n",
            "learning_rate: 0.1\n",
            "loss: msle\n",
            "units2: 24\n",
            "units3: 29\n",
            "units4: 9\n",
            "units5: 24\n",
            "units6: 18\n",
            "units7: 7\n",
            "units8: 11\n",
            "units9: 23\n",
            "units10: 27\n",
            "units11: 10\n",
            "units12: 10\n",
            "units13: 23\n",
            "units14: 26\n",
            "units15: 6\n",
            "units16: 14\n",
            "units17: 9\n",
            "units18: 10\n",
            "tuner/epochs: 2\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 4\n",
            "tuner/round: 0\n",
            "Score: 0.77533358335495\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "layers #: 6\n",
            "units0: 29\n",
            "activation: relu\n",
            "units1: 26\n",
            "learning_rate: 0.01\n",
            "loss: msle\n",
            "units2: 7\n",
            "units3: 17\n",
            "units4: 17\n",
            "units5: 24\n",
            "units6: 9\n",
            "units7: 8\n",
            "units8: 10\n",
            "units9: 28\n",
            "units10: 28\n",
            "units11: 20\n",
            "units12: 21\n",
            "units13: 14\n",
            "units14: 20\n",
            "units15: 29\n",
            "units16: 23\n",
            "units17: 19\n",
            "units18: 12\n",
            "units19: 13\n",
            "tuner/epochs: 34\n",
            "tuner/initial_epoch: 12\n",
            "tuner/bracket: 3\n",
            "tuner/round: 2\n",
            "tuner/trial_id: 0191\n",
            "Score: 0.7942997217178345\n",
            "6/6 [==============================] - 2s 5ms/step - loss: 50.4491\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 48.5852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DONE #"
      ],
      "metadata": {
        "id": "3MsjGfV4wRHa"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "83V7RsIbwbW6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}